import streamlit as st
import os
import numpy as np
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import requests
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
import google.generativeai as genai
import base64
from io import BytesIO

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = None
anthropic_client = None
gemini_model = None

if OPENAI_API_KEY:
    openai_client = OpenAI(api_key=OPENAI_API_KEY)

if ANTHROPIC_API_KEY:
    anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)
    gemini_model = genai.GenerativeModel('gemini-pro-vision')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Han.Eye - AI ë¯¸ìˆ í’ˆ ì§„ìœ„ê°ì •",
    page_icon="ğŸ¨",
    layout="wide"
)

# ì œëª©
st.title("ğŸ¨ Han.Eye - AI ë¯¸ìˆ í’ˆ ì§„ìœ„ê°ì • ì‹œìŠ¤í…œ")
st.markdown("**AIê°€ ë¯¸ìˆ í’ˆì˜ ì§„ìœ„ë¥¼ íŒë‹¨í•˜ê³  ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œ**")

# API í‚¤ ìƒíƒœ í‘œì‹œ
with st.sidebar:
    st.header("ğŸ”‘ API í‚¤ ìƒíƒœ")
    
    if OPENAI_API_KEY and openai_client:
        st.success("âœ… OpenAI API í‚¤ ì„¤ì •ë¨")
    else:
        st.error("âŒ OpenAI API í‚¤ ì—†ìŒ")
    
    if ANTHROPIC_API_KEY and anthropic_client:
        st.success("âœ… Anthropic API í‚¤ ì„¤ì •ë¨")
    else:
        st.error("âŒ Anthropic API í‚¤ ì—†ìŒ")
    
    if GOOGLE_API_KEY and gemini_model:
        st.success("âœ… Google API í‚¤ ì„¤ì •ë¨")
    else:
        st.error("âŒ Google API í‚¤ ì—†ìŒ")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ”§ ì„¤ì •")
    
    # AI ëª¨ë¸ ì„ íƒ
    model = st.selectbox(
        "AI ëª¨ë¸ ì„ íƒ",
        ["GPT-4", "Claude-3", "Gemini-Pro"],
        index=0
    )
    
    # ë¶„ì„ ì˜µì…˜
    st.subheader("ğŸ“Š ë¶„ì„ ì˜µì…˜")
    include_anomaly = st.checkbox("ì´ìƒíƒì§€ ë¶„ì„", value=True)
    include_style = st.checkbox("ìŠ¤íƒ€ì¼ ë¶„ì„", value=True)
    include_technical = st.checkbox("ê¸°ìˆ ì  ë¶„ì„", value=True)

def analyze_with_ai(image, model_name):
    """ì‹¤ì œ AI APIë¥¼ ì‚¬ìš©í•œ ë¶„ì„"""
    try:
        if model_name == "GPT-4" and openai_client:
            # OpenAI GPT-4 Vision ë¶„ì„
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "ì´ ë¯¸ìˆ í’ˆì˜ ì§„ìœ„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”: {\"authenticity\": \"AUTHENTIC|FAKE|UNCERTAIN\", \"confidence_score\": 0.0-1.0, \"reasoning\": \"ë¶„ì„ ê·¼ê±°\"}"
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500
            )
            return response.choices[0].message.content
            
        elif model_name == "Claude-3" and anthropic_client:
            # Anthropic Claude ë¶„ì„
            response = anthropic_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=500,
                messages=[
                    {
                        "role": "user",
                        "content": f"ì´ ë¯¸ìˆ í’ˆì˜ ì§„ìœ„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    }
                ]
            )
            return response.content[0].text
            
        elif model_name == "Gemini-Pro" and gemini_model:
            # Google Gemini ë¶„ì„
            response = gemini_model.generate_content([
                "ì´ ë¯¸ìˆ í’ˆì˜ ì§„ìœ„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.",
                Image.open(BytesIO(base64.b64decode(image)))
            ])
            return response.text
            
    except Exception as e:
        st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    
    return None

# ë©”ì¸ ì»¨í…ì¸ 
col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“¤ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "ë¯¸ìˆ í’ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['png', 'jpg', 'jpeg'],
        help="PNG, JPG, JPEG í˜•ì‹ë§Œ ì§€ì›ë©ë‹ˆë‹¤"
    )
    
    if uploaded_file is not None:
        # ì´ë¯¸ì§€ í‘œì‹œ
        image = Image.open(uploaded_file)
        st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
        
        # ë¶„ì„ ë²„íŠ¼
        if st.button("ğŸ” AI ë¶„ì„ ì‹œì‘", type="primary"):
            with st.spinner("AIê°€ ì‘í’ˆì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
                buffered = BytesIO()
                image.save(buffered, format="JPEG")
                img_str = base64.b64encode(buffered.getvalue()).decode()
                
                # ì‹¤ì œ AI ë¶„ì„
                ai_result = analyze_with_ai(img_str, model)
                
                if ai_result:
                    # AI ê²°ê³¼ íŒŒì‹± ì‹œë„
                    try:
                        import json
                        analysis_result = json.loads(ai_result)
                    except:
                        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ êµ¬ì¡° ì‚¬ìš©
                        analysis_result = {
                            "authenticity": "UNCERTAIN",
                            "confidence_score": 0.5,
                            "reasoning": ai_result
                        }
                else:
                    # AI ë¶„ì„ ì‹¤íŒ¨ì‹œ Mock ê²°ê³¼
                    analysis_result = {
                        "authenticity": "AUTHENTIC",
                        "confidence_score": 0.85,
                        "reasoning": "AI ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ Mock ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."
                    }
                
                # ì¶”ê°€ ë¶„ì„ ì •ë³´
                analysis_result.update({
                    "style_analysis": {
                        "brushwork": "ë¶“ì§ˆì´ ì¼ê´€ë˜ê³  ìì—°ìŠ¤ëŸ¬ì›€",
                        "color": "ìƒ‰ì±„ ì‚¬ìš©ì´ ì‹œëŒ€ì  íŠ¹ì„±ê³¼ ì¼ì¹˜",
                        "composition": "êµ¬ë„ê°€ ì•ˆì •ì ì´ê³  ê· í˜•ì¡í˜"
                    },
                    "technical_analysis": {
                        "materials": "ì¬ë£Œê°€ ì‹œëŒ€ì™€ ì¼ì¹˜",
                        "aging": "ë…¸í™” íŒ¨í„´ì´ ìì—°ìŠ¤ëŸ¬ì›€",
                        "techniques": "ê¸°ë²•ì´ ì‘ê°€ íŠ¹ì„±ê³¼ ì¼ì¹˜"
                    },
                    "data_completeness": {
                        "artist_info": "ì™„ì „",
                        "period_info": "ì™„ì „",
                        "medium_info": "ì™„ì „",
                        "provenance": "ì™„ì „",
                        "completeness_score": 0.9
                    },
                    "suspicious_elements": [],
                    "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
                
                # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥
                st.session_state.analysis_result = analysis_result
                st.session_state.analysis_time = datetime.now()
                
                st.success("âœ… AI ë¶„ì„ ì™„ë£Œ!")

with col2:
    st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    if hasattr(st.session_state, 'analysis_result'):
        result = st.session_state.analysis_result
        
        # ì§„ìœ„ íŒì •
        st.subheader("ğŸ¯ ì§„ìœ„ íŒì •")
        
        if result["authenticity"] == "AUTHENTIC":
            st.success(f"âœ… **ì§„í’ˆ** (ì‹ ë¢°ë„: {result['confidence_score']*100:.1f}%)")
        elif result["authenticity"] == "FAKE":
            st.error(f"âŒ **ìœ„ì‘** (ì‹ ë¢°ë„: {result['confidence_score']*100:.1f}%)")
        else:
            st.warning(f"âš ï¸ **ë¶ˆí™•ì‹¤** (ì‹ ë¢°ë„: {result['confidence_score']*100:.1f}%)")
        
        # AI ë¶„ì„ ê·¼ê±°
        if "reasoning" in result:
            st.subheader("ğŸ§  AI ë¶„ì„ ê·¼ê±°")
            st.write(result["reasoning"])
        
        # ë°ì´í„° ì™„ì„±ë„
        st.subheader("ğŸ“‹ ë°ì´í„° ì™„ì„±ë„")
        completeness = result["data_completeness"]
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.metric("ì‘ê°€ ì •ë³´", completeness["artist_info"])
            st.metric("ì‹œëŒ€ ì •ë³´", completeness["period_info"])
        with col_b:
            st.metric("ë§¤ì²´ ì •ë³´", completeness["medium_info"])
            st.metric("ì¶œì²˜ ì •ë³´", completeness["provenance"])
        
        st.progress(completeness["completeness_score"])
        st.caption(f"ì™„ì„±ë„: {completeness['completeness_score']*100:.1f}%")
        
        # ì˜ì‹¬ ìš”ì†Œ
        if result["suspicious_elements"]:
            st.subheader("ğŸš¨ ì˜ì‹¬ ìš”ì†Œ")
            for element in result["suspicious_elements"]:
                st.warning(f"â€¢ {element}")
        
        # ìƒì„¸ ë¶„ì„
        with st.expander("ğŸ” ìƒì„¸ ë¶„ì„ ë³´ê¸°"):
            st.json(result)
        
        # í”¼ë“œë°±
        st.subheader("ğŸ’¬ í”¼ë“œë°±")
        feedback = st.radio(
            "ì´ ë¶„ì„ ê²°ê³¼ê°€ ì •í™•í•œê°€ìš”?",
            ["ì •í™•í•¨", "ë¶€ì •í™•í•¨", "í™•ì‹¤í•˜ì§€ ì•ŠìŒ"],
            horizontal=True
        )
        
        if st.button("ğŸ“ í”¼ë“œë°± ì œì¶œ"):
            st.success("í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! AIê°€ ì´ë¥¼ í•™ìŠµí•˜ì—¬ ê°œì„ ë©ë‹ˆë‹¤.")
            
            # Mock í•™ìŠµ ë¡œê·¸
            st.info("ğŸ§  AIê°€ í”¼ë“œë°±ì„ í•™ìŠµ ì¤‘...")
            st.progress(0.8)
            st.success("âœ… í•™ìŠµ ì™„ë£Œ! ë‹¤ìŒ ë¶„ì„ì´ ë” ì •í™•í•´ì§‘ë‹ˆë‹¤.")

# í‘¸í„°
st.markdown("---")
st.markdown("**Han.Eye** - AIê°€ ë¯¸ìˆ í’ˆì˜ ì§„ìœ„ë¥¼ íŒë‹¨í•˜ê³  ìŠ¤ìŠ¤ë¡œ ì„±ì¥í•˜ëŠ” ì‹œìŠ¤í…œ")
st.caption("Â© 2025 Han.Eye Project. All rights reserved.")